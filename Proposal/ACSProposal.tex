\documentclass[11pt]{article}
\usepackage{a4wide,parskip,times}
\usepackage{hyperref}

\begin{document}

\centerline{\Large A tool for covertness benchmarking of Tor pluggable transports}
\vspace{2em}
\centerline{\Large \emph{An MPhil project proposal}}
\vspace{2em}
\centerline{\large Chongyang Shi (\emph{cs940}), Christ's College}
\vspace{1em}
\centerline{\large Project Supervisor: TBC}
\vspace{1em}

\begin{abstract}
\textsl{Censorship-circumventing Tor network traffic can be obfuscated as random traffic or traffic of a different protocol through the use of pluggable transport (PT) protocols. Past research efforts in means to detect obfuscated PT traffic have yielded various traffic analysis techniques, with varying performance and target protocol suitabilities. Inspired by related research on attacking image-watermarking systems, this proposed project intends to develop a benchmarking tool for evaluating the covertness of PT protocols through combinations of analysis techniques under current research. A baseline covertness against traffic classification could be established for development of new PT protocols.} 
\end{abstract}

\section{Introduction, approach and outcomes}

Tor is a popular tool for anonymised and censorship-resistant network communications. While it is trivial for a network node in a privileged position to detect and block non-obfuscated Tor traffic \cite[Tb. 6] {bujlow2015independent} in a process called \emph{traffic classification}, Tor provides a set of \emph{pluggable transport} (PT) tools which clients can use to conceal their connections to a Tor bridge node from such censors. An arms race between state-sponsored censors and PT developers in traffic obfuscation has been going on for many years \cite{khattak2014systemization}. 

Among pluggable transports, two classes of techniques currently exist to achieve obfuscation of the encrypted traffic: pseudo-random transformation and mimicry of other ``legitimate'' protocols. Techniques in the former class attempt to avoid traffic classification by transforming Tor traffic into pseudo-random data, while those in the latter class transform Tor traffic into the likes of various other protocols that will result in too much collateral damage for the censor to block. A number of tools have been developed in each class and deployed with Tor distributions, with pseudo-random transformation represented by ScrambleSuit \cite{winter2013scramblesuit} and Format-Transforming Encryption (FTE) \cite{dyer2013protocol}, and mimicry represented by meek \cite{fifield2015blocking} and SkypeMorph \cite{mohajeri2012skypemorph}. 

Obfuscation techniques can generally be evaluated on two metrics: the transmission performance after obfuscation, and the covertness of obfuscated traffic in regular traffic when examined by a state censor. For the purpose of censorship-circumvention, interests are usually concentrated on the latter. There has been a few independent covertness evaluations on the aforementioned tools \cite{tan2015towards} \cite{houmansadr2013parrot} \cite{wang2015seeing} over recent years. This is however still a relatively niche field of research when compared with related fields such as cipher cryptanalysis and steganography, whose methodologies and techniques could be adapted into use in this field.

Under current research efforts, three categories of attack techniques are used to detect obfuscated traffic: semantics-based attacks where behaviour of traffic is checked against expected behaviours of its protocol \cite[Sec. VIII]{houmansadr2013parrot} \cite[Sec. 4]{wang2015seeing}; entropy-based attacks where entropy signatures of packet payloads can be established for regular and obfuscated traffic \cite{tan2015towards} \cite[Sec. 5]{wang2015seeing}; and machine learning-based attacks that can be effective against protocols resistant to two previous categories of attacks \cite[Sec. 6]{wang2015seeing}, but with significant drawbacks in portability between network environments \cite{dixon2016network}. 

All categories of attacks observe features in traffic traces such as packet metadata and distribution. Each category of technique has distinct superiorities and weaknesses in terms of computational cost, protocol coverage, and portability. They share the same the goal of achieving a high true-positive rate (identifying obfuscated traffic traces) and a low false-positive rate (not misidentifying non-obfuscated traffic as obfuscated), both of which are desirable to a state censor. 

Therefore, the primary objective of this proposed project is to produce a benchmarking tool encompassing adapted versions of the aforementioned detection techniques. The tool will be able to accept sample traffic traces of any PT suitable for use with Tor, and perform varying combinations of traffic analysis techniques to evaluate the covertness of the PT protocol. Combinations of techniques can be chosen with deliberate strategies to maximise detection performance, as observed by Wang et al. \cite[Sec. 5.2]{wang2015seeing}. There is the possibility of automating the selection process. With varying thresholds on acceptable true-positive and false-negative rates, it would be possible to estimate whether a PT protocol is of required covertness standards, as performed by StirMark \cite{petitcolas1998attacks} on image-watermarking systems.

Traffic traces used in this proposed study could be sourced from anonymised internet traces available for research purposes, injected with self-generated PT traffic traces, as conducted by Wang \emph{et. al.} \cite[Sec. 3]{wang2015seeing}. Alternatively, for traffic traces more resembling real network conditions, human volunteers can be invited to browse the internet in a monitored environment where Tor clients with PT are in use on some of the network clients, subject to ethical review approval.


\section{Workplan (500 words)}

With existing implementations of some detection techniques by Wang et. al. \cite{wang2015seeing} \footnote{https://github.com/liangw89/obfs-detection} to consult from, there is a reasonable level of confidence that individual detection techniques can effectively detect obfuscated traffic to some degree, despite the fact that Tor and pluggable transports have evolved since the publication of their work. In the process of developing a benchmarking tool encompassing these techniques, the primary matter of concern is to adapt and improve these techniques so that they could be combined for more accurate PT detection. 

% Something about traffic

% Week-by-week breakdown. 

\bibliographystyle{IEEEtran}
\footnotesize{\bibliography{proposal}}

\newpage
\appendix

\end{document}
